HateShield - Online Hate Speech Detection Model
Overview
HateShield is an AI-based detection model designed to identify hate speech and cyberbullying content in online communication platforms. This model utilizes state-of-the-art natural language processing techniques to analyze text data and classify it based on its potential to incite hatred or aggression.

Dataset
To train and evaluate HateShield, the Cyberbullying Dataset from Kaggle has been utilized. Specifically, the aggression_parsed_dataset.csv file from the dataset has been employed. This dataset contains a collection of text samples labeled with categories such as '1' for hateful, and '0' for not hateful, providing a comprehensive basis for training and testing the HateShield model.
